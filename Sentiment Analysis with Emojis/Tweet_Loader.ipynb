{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sending GET requests from the API\n",
    "import requests\n",
    "# For saving access tokens and for file management when creating and adding to the dataset\n",
    "import os\n",
    "# For dealing with json responses we receive from the API\n",
    "import json\n",
    "# For displaying the data after\n",
    "import pandas as pd\n",
    "# For saving the response data in CSV format\n",
    "import csv\n",
    "# For parsing the dates received from twitter in readable formats\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "#To add wait time between requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To set your enviornment variables in your terminal run the following line:\n",
    "# export 'BEARER_TOKEN'='<your_bearer_token>'\n",
    "bearer_token = os.environ.get(\"BEARER_TOKEN\")\n",
    "\n",
    "def create_url(id):\n",
    "    tweet_fields = \"tweet.fields=lang\"\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    ids = \"ids=\" + id\n",
    "    #\n",
    "    # You can adjust ids to include a single Tweets.\n",
    "    # Or you can add to up to 100 comma-separated IDs\n",
    "    url = \"https://api.twitter.com/2/tweets?{}&{}\".format(ids, tweet_fields)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer <BearerToken>\"\n",
    "    r.headers[\"User-Agent\"] = \"v2TweetLookupPython\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url):\n",
    "    response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet(id):\n",
    "    url = create_url(id)\n",
    "    json_response = connect_to_endpoint(url)\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_early = pd.read_fwf('Covid_Tweets_03.03.20-10.03.20.txt', header = None)\n",
    "df_late = pd.read_fwf('Covid_Tweets_27.11.20-03.12.20.txt', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    #Early\n",
    "    early_ids = df_early.iloc[:,0].values.tolist()\n",
    "    \n",
    "    early_id_list = []\n",
    "    while len(early_ids) > 100 :\n",
    "        early_id_str = \"\"\n",
    "        for i in range(100):\n",
    "            if(i<99):\n",
    "                early_id_str = early_id_str+str(early_ids.pop())+\",\"\n",
    "            else:\n",
    "                early_id_str = early_id_str+str(early_ids.pop())\n",
    "        early_id_list.append(early_id_str)\n",
    "    early_id_str = \"\"\n",
    "    x = len(early_ids)\n",
    "    for i in range(x):\n",
    "            if(i<x-1):\n",
    "                early_id_str = early_id_str+str(early_ids.pop())+\",\"\n",
    "            else:\n",
    "                early_id_str = early_id_str+str(early_ids.pop())\n",
    "    early_id_list.append(early_id_str)\n",
    "\n",
    "    del early_id_list[5000:]\n",
    "    \n",
    "    \n",
    "    #Late\n",
    "    late_ids = df_late.iloc[:,0].values.tolist()\n",
    "    \n",
    "    late_id_list = []\n",
    "    while len(late_ids) > 100 :\n",
    "        late_id_str = \"\"\n",
    "        for i in range(100):\n",
    "            if(i<99):\n",
    "                late_id_str = late_id_str+str(late_ids.pop())+\",\"\n",
    "            else:\n",
    "                late_id_str = late_id_str+str(late_ids.pop())\n",
    "        late_id_list.append(late_id_str)\n",
    "    late_id_str = \"\"\n",
    "    x = len(late_ids)\n",
    "    for i in range(x):\n",
    "            if(i<x-1):\n",
    "                late_id_str = late_id_str+str(late_ids.pop())+\",\"\n",
    "            else:\n",
    "                late_id_str = late_id_str+str(late_ids.pop())\n",
    "    late_id_list.append(late_id_str)\n",
    "    print(len(late_id_list))\n",
    "    late_id_list = del late_id_list[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_early_tweets():  \n",
    "    file = open('early-covid-tweets.csv', 'w+', newline ='', encoding='utf-8') \n",
    "    with file: \n",
    "        while len(early_id_list) > 300:\n",
    "            for i in range(300):\n",
    "                json_tweet = get_tweet(early_id_list.pop())\n",
    "                if \"data\" in json_tweet.keys():\n",
    "                    for x in json_tweet['data']:\n",
    "                        if x['lang'] == \"en\":\n",
    "                            write = csv.writer(file)\n",
    "                            y = str(x['text'])\n",
    "                            write.writerow([y]) \n",
    "            print(\"sleep\")\n",
    "            time.sleep(900)\n",
    "        x = len(early_id_list)\n",
    "        for i in range(x):\n",
    "            json_tweet = get_tweet(early_id_list.pop())\n",
    "            if \"data\" in json_tweet.keys():\n",
    "                    for x in json_tweet['data']:\n",
    "                        if x['lang'] == \"en\":\n",
    "                            write = csv.writer(file) \n",
    "                            y = str(x['text'])\n",
    "                            write.writerow([y]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_late_tweets():  \n",
    "    file = open('late-covid-tweets.csv', 'w+', newline ='', encoding='utf-8') \n",
    "    with file: \n",
    "        while len(late_id_list) > 300:\n",
    "            print(len(late_id_list))\n",
    "            for i in range(300):\n",
    "                json_tweet = get_tweet(late_id_list.pop())\n",
    "                if \"data\" in json_tweet.keys():\n",
    "                    for x in json_tweet['data']:\n",
    "                        if x['lang'] == \"en\":\n",
    "                            write = csv.writer(file)\n",
    "                            y = str(x['text'])\n",
    "                            write.writerow([y]) \n",
    "            time.sleep(900)\n",
    "        x = len(late_id_list)\n",
    "        for i in range(x):\n",
    "            json_tweet = get_tweet(late_id_list.pop())\n",
    "            if \"data\" in json_tweet.keys():\n",
    "                    for x in json_tweet['data']:\n",
    "                        if x['lang'] == \"en\":\n",
    "                            write = csv.writer(file) \n",
    "                            y = str(x['text'])\n",
    "                            write.writerow([y]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5320\n",
      "3473\n",
      "3173\n",
      "2873\n",
      "2573\n",
      "2273\n",
      "1973\n",
      "1673\n",
      "1373\n",
      "1073\n",
      "773\n",
      "473\n"
     ]
    }
   ],
   "source": [
    "reset()\n",
    "get_early_tweets()\n",
    "get_late_tweets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
